{
  "hash": "24522936e0f28f9998e96a067f14724a",
  "result": {
    "markdown": "---\ntitle: 'Classification Blog'\ndate: '2023-11-28'\ncategories: ['Machine Learning', 'Classification', 'Random Forest']\ndescription: 'This post walks through data analysis using Classification techniques such as Random Forest.'\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n# Background\n\nThis blog post will walk through data analysis with Classification. The data set contains several data points on individuals and which drug they were administered. These data points include information of each individual's age, sex, blood pressure, cholesterol, sodium to potassium ratio, and the drug they were administered. The goal here is to determine what factors determine which drug to administer to the individual, as well as find which factors play a big role in the drug classification. This classification will be used to predict which drug should be administered to future patients based on the factors provided. \n\n## Setup\n\nWe will first begin by checking our python version and importing the necessary libraries for this. We will use Pandas to read the csv file and manipulate its data, and matplotlib's pyplot to display graphs and plot our data. Scikit learn (sklearn) libraries will also be imported for its metrics, model selection, finding importance of features, and the classifier. \n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport sys\n\n#Project requires Python 3.7 or above\nassert sys.version_info >= (3, 7)\n\n# import libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_recall_curve, precision_score, recall_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_selection import SelectFromModel\n```\n:::\n\n\n### Data\n\nLet's start by seeing what our data looks like.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Read data\ndata = pd.read_csv(\"drug.csv\")\nprint(data.shape)\ndata.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(200, 6)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>BP</th>\n      <th>Cholesterol</th>\n      <th>Na_to_K</th>\n      <th>Drug</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>25.355</td>\n      <td>DrugY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>13.093</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>10.114</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>7.798</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>61</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>18.043</td>\n      <td>DrugY</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe dimensions of the data is (200, 6), which means that the data has 6 columns per each individual: Age, Sex, Blood Pressure (BP), Cholesterol, Sodium to Potassium Ratio (Na_to_K), and Drug. There are 200 entries in the data set, which is generally considered a low amount of data to have, but for our purposes we will make do with this. We will see how these factors of each individual play a role in what drug they are administered.\n\n### Plotting the Data\n\nTo gain a better understanding of the data, we can visualize it by plotting some of the factors.\n\n### Plotting the Data\n\nLet's first look at the different types of drugs that were administered and their frequencies in the data set.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nplt.hist(data['Drug'], rwidth=0.5)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n(array([91.,  0., 16.,  0.,  0., 54.,  0., 23.,  0., 16.]),\n array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n <BarContainer object of 10 artists>)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-4-output-2.png){width=575 height=411}\n:::\n:::\n\n\nIt appears that Drug Y was the most frequently administered drug, with Drug X coming in second. In total, there were 5 types of drugs that were administered, but the remaining three were administered significantly less than Drug Y and Drug X.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nplt.hist(data['Age'], rwidth=0.5)\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n(array([16., 22., 20., 20., 21., 28., 16., 23., 18., 16.]),\n array([15. , 20.9, 26.8, 32.7, 38.6, 44.5, 50.4, 56.3, 62.2, 68.1, 74. ]),\n <BarContainer object of 10 artists>)\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-5-output-2.png){width=566 height=411}\n:::\n:::\n\n\nThe age groups seem to roughly evenly distributed. There appears to be an equal amount of individuals below 50 and above 50, and no significant outlying age group.\n\nLet's try plotting Age against the Drug type to see what information that may provide.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nplt.xlabel('Drug Type')\nplt.ylabel('Age')\nplt.scatter(data['Drug'], data['Age'])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-6-output-1.png){width=585 height=429}\n:::\n:::\n\n\nThis somewhat matches our expectations, as we see more data points for Drug Y and Drug X since those were the most frequently administered drugs. Drug C has very few points and is roughly evenly spread out among all age groups. Drug A seems to be only administered for individuals below 50, while Drug B seems to be only administered for individuals above 50.\n\nLet's try a similar plot, but this time plotting the Sodium to Potassium ratio against the Drug Type.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nplt.xlabel('Drug Type')\nplt.ylabel('Sodium to Potassium Ratio')\nplt.scatter(data['Drug'], data['Na_to_K'])\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-7-output-1.png){width=585 height=429}\n:::\n:::\n\n\nThose with a ratio of over 15 were always administered Drug Y. If the ratio was below 15, then any one of the other four drug types were given. This indicates that the Sodium to Potassium ratio plays a huge role in classifying which drug should be applied.\n\n\n### Performing the Classification\n\nNow that we have looked at a few data points and gotten a better understanding of what we are looking for and what to expect, we can begin preparing the data to be placed into our Classification model. The data will of course need to be split into training and testing sets, for which the standard 80-20 convention will be followed. \n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# Prepare data and do split data into training and test groups (Using standard 80-20 split)\nX = data[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']]\nX = pd.get_dummies(X) # Convert categorical vars to indicator vars\nY = data['Drug']\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, shuffle=True, random_state=42)\nprint(\"X-Training Set Dimensions: \", X_train.shape)\nprint(\"X-Test Set Dimensions: \", X_test.shape)\nprint(\"Y-Training Set Dimensions: \", Y_train.shape)\nprint(\"Y-Test Set Dimensions: \", Y_test.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nX-Training Set Dimensions:  (160, 9)\nX-Test Set Dimensions:  (40, 9)\nY-Training Set Dimensions:  (160,)\nY-Test Set Dimensions:  (40,)\n```\n:::\n:::\n\n\nWe use the Pandas get_dummies() method to convert any categorical variables that we have into 1/0 indicator values. For example, our data would indicate Cholesterol as either HIGH, NORMAL, or LOW. This pandas method will split the data into three new categories called BP_HIGH, BP_NORMAL, and BP_Low. In these categories, a 1 will indicate that this is true for the indivdual, and a 0 will indicate that it is not true. This is applied for all parts of the data set.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Display what Pandas get_dummies has done to the data set.\nX.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Na_to_K</th>\n      <th>Sex_F</th>\n      <th>Sex_M</th>\n      <th>BP_HIGH</th>\n      <th>BP_LOW</th>\n      <th>BP_NORMAL</th>\n      <th>Cholesterol_HIGH</th>\n      <th>Cholesterol_NORMAL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>25.355</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47</td>\n      <td>13.093</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>10.114</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>7.798</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>61</td>\n      <td>18.043</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Performing Classification - Model Analysis\n\nWe can now go through with the Classification, for which we will use the Random Forest Classification Algorithm. We will do a cross validation to see the expected level of fit for our model to the data set.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Use Random Forest for Classification\nforest = RandomForestClassifier(n_estimators=200, random_state=42)\ncross = cross_val_predict(forest, X_train, Y_train, cv=None, method=\"predict_proba\")\ncross[:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([[0.01 , 0.03 , 0.   , 0.03 , 0.93 ],\n       [0.   , 0.   , 0.005, 0.   , 0.995],\n       [0.01 , 0.01 , 0.   , 0.   , 0.98 ],\n       [0.96 , 0.   , 0.   , 0.02 , 0.02 ],\n       [0.99 , 0.   , 0.   , 0.   , 0.01 ]])\n```\n:::\n:::\n\n\nWe can also find the cross validation score to understand the model's performance better and how accurate it is. The cross_val_score method will be used, and we will use the default cross validation (cv) of 5, so this model is trained/tested on 5 differents subsets of the data.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\ncross_val_score(forest, X_train, Y_train, scoring='accuracy')\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\narray([1.     , 1.     , 1.     , 0.96875, 1.     ])\n```\n:::\n:::\n\n\nThe model seems to work really well, as our accuracy scores are very high for each section.\n\n\n### Performing Classification - Random Forest\n\nWe can now go ahead and fit our model to the Random Forest model we plan to use.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nforest.fit(X_train, Y_train)\npredict = forest.predict(X_test)\n```\n:::\n\n\nWe will now apply the Precision/Recall method using sklearn's metrics precision and recall to determine how well our Classification model did. The precision will compare the number of true positive and false positives, and the recall will compare true positives and false negatives. From sklearn's metrics we will also find the accuracy score to see how accurate our model is.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# precision = tp / (tp + fp)\nprint(\"Precision Scores: \", precision_score(Y_test, predict, average=None))\n\n# recall = tp / (tp + fn)\nprint(\"Recall Scores: \", recall_score(Y_test, predict, average=None))\n\nprint(\"Random Forest Model Accuracy: \", accuracy_score(Y_test, predict))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPrecision Scores:  [1. 1. 1. 1. 1.]\nRecall Scores:  [1. 1. 1. 1. 1.]\nRandom Forest Model Accuracy:  1.0\n```\n:::\n:::\n\n\nFor every performance metric our model shows a 1.0, indicating it is 100% accurate to compared to the data set. This means that our model produces no false positives or false negatives. The Random Forest classifier fits the data very well.\n\n\nWe can also look at it side-by-side through a table, and see how the model predicted performance comapres to the actual performance.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# Side by Side comparison\npd.DataFrame({\"Actual Performance: \" : Y_test[:10], \"Model Predicted Performance\" : predict[:10]})\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Performance:</th>\n      <th>Model Predicted Performance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>95</th>\n      <td>drugX</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>DrugY</td>\n      <td>DrugY</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>drugX</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>158</th>\n      <td>drugC</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>128</th>\n      <td>DrugY</td>\n      <td>DrugY</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>DrugY</td>\n      <td>DrugY</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>DrugY</td>\n      <td>DrugY</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>drugX</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>174</th>\n      <td>drugA</td>\n      <td>drugA</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>drugX</td>\n      <td>drugX</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Feature Importance\n\nNow that we see how well our model works, let's look at which factors, or features, our Random Forest actually used to make decisions. As we noticed at the beginning, there were some features that appeared to heavily influence which drug was chosen. \n\nWe will use sklearn's feature selection capabilities for this through the SelectFromModel option. This will give us the ability to look at what features were used.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# Let's look at which features were the most important. Using select from model\nmodel = SelectFromModel(RandomForestClassifier(n_estimators=200, random_state=42))\nmodel.fit(X_train, Y_train)\nmodel.get_support()[:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\narray([ True,  True, False, False,  True])\n```\n:::\n:::\n\n\nThis tells us that 3 of the 5 features given were used by the model to perform the classification. This is useful, but we also want to know exactly which 3 features were used, and will have to display that.\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# See which features were used by Random Forest\nfeatures = X_train.columns[(model.get_support())]\nprint(features)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIndex(['Age', 'Na_to_K', 'BP_HIGH'], dtype='object')\n```\n:::\n:::\n\n\nThe 3 features used were Age, Sodium to Potassium ratio, and BP_HIGH. These 3 features had the biggest impact in decision making, so they were used by the classifier. As we analyzed above from the plots, we saw how Age and the Sodium to Potassium ratio did seem to affect which drug was administered, so this was expected.\n\nLet's plot the distribution of our features importance, to see how important each was. We will set our nlargest to 3, so that our 3 main features will be displayed.\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\npd.Series(model.estimator_.feature_importances_, index=X.columns).nlargest(3).plot(kind='barh')\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\n<Axes: >\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](Classification_files/figure-html/cell-17-output-2.png){width=608 height=411}\n:::\n:::\n\n\nIt appears that the Sodium to Potassium ratio was by far the most important factor in the model's classification, when it comes to deciding which drug to administer.\n\n",
    "supporting": [
      "Classification_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}