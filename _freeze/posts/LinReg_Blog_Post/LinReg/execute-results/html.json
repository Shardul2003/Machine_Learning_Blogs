{
  "hash": "cad5daa9036c46d4bd59c0b17298fb60",
  "result": {
    "markdown": "---\ntitle: 'Linear Regression Blog'\ndate: '2023-11-28'\ncategories: ['Machine Learning', 'Linear Regression']\ndescription: 'This post covers a dataset I analyze using Linear Regression.'\nexecute: \n  message: false\n  warning: false\neditor_options: \n  chunk_output_type: console\n---\n\n# Background\n\nThis blog post will cover data analysis with multiple Linear Regression. The data set holds information on the performance of students along with their sleep hours, study hours, previous scores, practiced questions, and extracurricular participation. The goal here, is to identify how these factors affect a student's performance index. To do this, a multiple Linear Regression will be performed on the data set to analyze whether a correlation does in fact exist.\n\n## Setup\n\nWe will first begin by checking our python version and importing the necessary libraries for this. We will use Pandas to read the csv file and manipulate its data, numpy for array building, matplotlib's pyplot to display graphs and plot our data. Scikit learn (sklearn) libraries will also be imported to help perform the Linear Regression.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport sys\n\n#Project requires Python 3.7 or above\nassert sys.version_info >= (3, 7)\n\n# import libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n```\n:::\n\n\n### Data\n\nLet's start by seeing what our data looks like.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# Read data\ndata = pd.read_csv(\"Student_Performance.csv\")\nprint(data.shape)\ndata.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(10000, 6)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hours Studied</th>\n      <th>Previous Scores</th>\n      <th>Extracurricular Activities</th>\n      <th>Sleep Hours</th>\n      <th>Sample Question Papers Practiced</th>\n      <th>Performance Index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>99</td>\n      <td>Yes</td>\n      <td>9</td>\n      <td>1</td>\n      <td>91.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>82</td>\n      <td>No</td>\n      <td>4</td>\n      <td>2</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>51</td>\n      <td>Yes</td>\n      <td>7</td>\n      <td>2</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>52</td>\n      <td>Yes</td>\n      <td>5</td>\n      <td>2</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>75</td>\n      <td>No</td>\n      <td>8</td>\n      <td>5</td>\n      <td>66.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe dimensions of the data is (10000, 6), which means that the data has 6 columns: Hours Studied, Previous Scores, Extracurricular Activities, Sleep Hours, Sample Question Papers Practiced, and Performance Index. These 6 categories are provided for each student, and there are 10,000 student entries present in the data set. We want to see how the first 5 factors affect a student's Performance Index.\n\n### Plotting the Data\n\nTo understand and visualize how each factor individually affects student Performance Index, we will plot the data for each factor.\n\n### Plotting the Data\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nplt.xlabel('Hours Studied')\nplt.ylabel('Performance')\nplt.scatter(data['Hours Studied'], data['Performance Index'], color='red', marker='+')\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n<matplotlib.collections.PathCollection at 0x12fee1750>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](LinReg_files/figure-html/cell-4-output-2.png){width=593 height=429}\n:::\n:::\n\n\nHours Studied does seem to have a correlation to a student's Performance Index. A general trend that appears to be present is that the longer a student studies, the more likely they are to perform better.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nplt.xlabel('Previous Scores')\nplt.ylabel('Performance')\nplt.scatter(data['Previous Scores'], data['Performance Index'], color='red', marker='+')\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n<matplotlib.collections.PathCollection at 0x12ff6fa90>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](LinReg_files/figure-html/cell-5-output-2.png){width=593 height=429}\n:::\n:::\n\n\nPrevious scores appear to have a significant correlation to Performance Index. The better the student's score previously, the more likely they are to have higher performance.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nlabels = ['no', 'yes']\nplt.pie(data['Extracurricular Activities'].value_counts(), labels=labels, autopct='%1.0f%%')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](LinReg_files/figure-html/cell-6-output-1.png){width=389 height=389}\n:::\n:::\n\n\nThis shows us the number of student's participating in Extracurricular Activities. Because the data is provided in Yes or No format, a pie chart makes the most sense to visualize this data. The numbers of students who participate and do not are roughly about the same, with slightly more student not participating in Extracurricular Activites.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nplt.xlabel('Sleep Hours')\nplt.ylabel('Performance')\nplt.scatter(data['Sleep Hours'], data['Performance Index'], color='red', marker='+')\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\n<matplotlib.collections.PathCollection at 0x12fffcc90>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](LinReg_files/figure-html/cell-7-output-2.png){width=593 height=429}\n:::\n:::\n\n\nThe data is spread out fairly similarly. This may indicate that the number of hours slept does not have a significant impact on a student's performance.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nplt.xlabel('Sample Questions Practices')\nplt.ylabel('Performance')\nplt.scatter(data['Sample Question Papers Practiced'], data['Performance Index'], color='red', marker='+')\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n<matplotlib.collections.PathCollection at 0x130074690>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](LinReg_files/figure-html/cell-8-output-2.png){width=593 height=429}\n:::\n:::\n\n\nLooking at the Sample Questions Practiced, it also appears as if the data is about evenly spread out, indicating that it may not have much of an impact on student performance.\n\n### Performing the Linear Regression\n\nBefore we dive into the Linear Regression, we will have to prepare our data and also split the data set into its respective training and testing sets. For splitting the data, we will use the standard 80-20 split, where 80% of our data will be used to train our multiple Linear Regression model, and the remaining 20% will be used to test the model.\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# Prep model, split data into training and testing groups (follow standard 80-20 split)\n# Change the yes/no to 1/0 to fit Linear Regression\ndata['Extracurricular Activities'].replace(('Yes', 'No'), (1, 0), inplace=True)\nX = data[['Hours Studied', 'Previous Scores', 'Extracurricular Activities', 'Sleep Hours', 'Sample Question Papers Practiced']]\nY = data['Performance Index']\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=42)\nprint(\"X-Training Set Dimensions: \", X_train.shape)\nprint(\"X-Test Set Dimensions: \", X_test.shape)\nprint(\"Y-Training Set Dimensions: \", Y_train.shape)\nprint(\"Y-Test Set Dimensions: \", Y_test.shape)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nX-Training Set Dimensions:  (8000, 5)\nX-Test Set Dimensions:  (2000, 5)\nY-Training Set Dimensions:  (8000,)\nY-Test Set Dimensions:  (2000,)\n```\n:::\n:::\n\n\nNow that our data has been fixed and placed into its respective groups as expected, we can begin with the performing the Linear Regression.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# Create Linear Regression Model\nreg = LinearRegression()\nreg.fit(X_train, Y_train)\npredict = reg.predict(X_test)\n```\n:::\n\n\nThe sklearn library allows us to conduct a Linear Regression. We will fit the data to the model so that it can perform the Linear Regression, and then use the predict functionality on our test set to get a set of the predicted values.\n\n### Accuracy of Model\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# Check model accuracy to determine how well it fits the actual performance\nreg.score(X_test, Y_test)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n0.9889832909573145\n```\n:::\n:::\n\n\nThe score functionality is similar to producing an r-value to find correlation. The value we have, which is roughly 0.989, indicates our model is very accurate, and that a strong correlation exists between the model predicted values and the actual values.\n\nWe can plot the predicted value against the actual values to better visualize how well the model fits the data set.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.title('Actual vs Predicted Values')\n\nplt.scatter(Y_test, predict, color='red', marker='+')\narr = np.array(Y_test)\narr2 = np.array(predict)\nplt.plot([10, 20, 40, 60, 80, 100], [10, 20, 40, 60, 80, 100], \"b-\", label=\"Predictions\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](LinReg_files/figure-html/cell-12-output-1.png){width=593 height=449}\n:::\n:::\n\n\nLet's also take a look at this in table format using the Pandas DataFrame functionality, which will allow us to get a side-by-side comparison of the results.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\npd.DataFrame({\"Actual Performance: \" : Y_test[:10], \"Model Predicted Performance\" : predict[:10]})\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual Performance:</th>\n      <th>Model Predicted Performance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6252</th>\n      <td>51.0</td>\n      <td>54.711854</td>\n    </tr>\n    <tr>\n      <th>4684</th>\n      <td>20.0</td>\n      <td>22.615513</td>\n    </tr>\n    <tr>\n      <th>1731</th>\n      <td>46.0</td>\n      <td>47.903145</td>\n    </tr>\n    <tr>\n      <th>4742</th>\n      <td>28.0</td>\n      <td>31.289767</td>\n    </tr>\n    <tr>\n      <th>4521</th>\n      <td>41.0</td>\n      <td>43.004570</td>\n    </tr>\n    <tr>\n      <th>6340</th>\n      <td>59.0</td>\n      <td>59.071252</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>48.0</td>\n      <td>45.903475</td>\n    </tr>\n    <tr>\n      <th>5202</th>\n      <td>87.0</td>\n      <td>86.459118</td>\n    </tr>\n    <tr>\n      <th>6363</th>\n      <td>37.0</td>\n      <td>37.700140</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>73.0</td>\n      <td>72.055925</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe predicted values are very close to the actual values, and we see in the table how some differ more than others. In the first row, the two values differ by about 3 points, but in row 6 the values differ by only about 0.7 points.\n\nNow, let's find out what our linear equation actually is for this model we built. To do this, we will have to find the coefficients the model created for each factor, as well as our y-intercept.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nprint(\"Coefficients: \", reg.coef_)\nprint(\"Y-intercept: \", reg.intercept_)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCoefficients:  [2.85248393 1.0169882  0.60861668 0.47694148 0.19183144]\nY-intercept:  -33.92194621555529\n```\n:::\n:::\n\n\nThe coefficients are listed in the order the data was passed in, and from this information we can get our equation. The Linear Regression formula is:\n\n**2.85(Hours Studied) + 1.02(Previous Scores) + 0.61(Extracurricular Activities) + 0.48(Sleep Hours) + 0.19(Sample Questions) - 33.92**\n\n",
    "supporting": [
      "LinReg_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}